{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8Zg8-3oA6Ie"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets torch torchvision evaluate gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import gradio as gr\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    ViTImageProcessor,\n",
        "    ViTForImageClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")"
      ],
      "metadata": {
        "id": "-Q6G1Yja7b-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "wKxFowi47mKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = load_dataset(\"zacharielegault/PatchCamelyon\", split='train', streaming=True)\n",
        "dataset_subset = list(raw_dataset.take(5000))"
      ],
      "metadata": {
        "id": "BDkLGM1x72Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/vit-base-patch16-224\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "def transform_medical_images(examples):\n",
        "    inputs = processor(examples['image'], return_tensors='pt')\n",
        "    inputs['labels'] = examples['label']\n",
        "    # .squeeze() here prevents the dimension error later!\n",
        "    inputs['pixel_values'] = inputs['pixel_values'].squeeze()\n",
        "    return inputs\n",
        "\n",
        "processed_dataset = [transform_medical_images(ex) for ex in dataset_subset]"
      ],
      "metadata": {
        "id": "tN7hn3Cl8AEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {0: \"Healthy\", 1: \"Malignant\"}\n",
        "label2id = {\"Healthy\": 0, \"Malignant\": 1}\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IBM2HUqK8KUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-cancer-model\",\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=5e-6,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True if torch.cuda.is_available() else False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "dw1YOPKd_Ywk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Training...\")\n",
        "trainer.train()\n",
        "print(\"Training Complete!\")"
      ],
      "metadata": {
        "id": "YzisHlEN_qsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "uJMOweytBFF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"cancer-ai-model\")\n",
        "processor.push_to_hub(\"cancer-ai-model\")"
      ],
      "metadata": {
        "id": "AcFHUlyiC8hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "61Zwwa4FIlqm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}